{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Erudio logo](img/erudio-logo-small.png)\n",
    "---\n",
    "![Sklearn logo](img/scikit-learn-logo-small.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beginning Machine Learning with scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous Target Values\n",
    "\n",
    "For a regression, we want a range of target values, not a binary category. Having one-hot encoded binary features with a target that is more ordinal than continuous is close to the worst case for using a regression. It's time to move away from the \"Learning about Humans learning ML\" dataset. We will use a well-known example dataset that is included with scikit-learn for this next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.setup import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Datasets\n",
    "\n",
    "A number of sample datasets are included with scikit-learn, either already bundled with a `load_*()` function for the smaller ones or with a `fetch_*()` function for the larger ones that can be obtained online. The `make_*()` functions create synthetic datasets with some randomness in their generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "[attr for attr in dir(datasets) if not attr.startswith('_')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## California Housing Data\n",
    "\n",
    "One downloadable dataset is the California housing data.  It has a target of house price, and 8 features.  There are 20 thousands samples in it, so it is reasonably large sized.  That is, it is nowhere close to the modern datasets of millions or billions of observations we sometimes work with; but it is also not a toy dataset of dozens or hundreds of observations that are often shown for demonstration purposes (including in prior lessons of this course)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To demonstrate downloading, remove cached version of dataset\n",
    "!ls ~/scikit_learn_data\n",
    "!rm ~/scikit_learn_data/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "california = datasets.fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(california.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, it is often useful to massage the standard format of scikit-learn dataset objects.  These objects all have a attributes `.DESCR`, `.feature_names`, `.data`, `.target`.  The latter two are NumPy arrays.  The feature names are simply a Python list of strings.  The description is a single string that has newlines and simple formatting with citations and links inside it.\n",
    "\n",
    "The California housing dataset has a fairly brief description.  For comparison, the Boston housing dataset had fewer observations but more citational detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if you try to load the Boston dataset, you'll get a message stating that this dataset has been removed from scikit-learn since version 1.2.\n",
    "\n",
    "Boston Housing Prices dataset has an ethical problem: the authors of this dataset constructed a non-invertible variable \"B\" assuming that racial self-segregation has a positive effect on housing prices. Furthermore, the goal of the research that led to the creation of this dataset was to study the impact of air quality, but it did not adequately demonstrate the validity of this assumption.\n",
    "\n",
    "The scikit-learn maintainers therefore strongly discourage the use of this dataset unless the purpose of the code is to study and educate about ethical issues in data science and machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative with more variables than the California housing dataset is the\n",
    "[Ames, Iowa housing\n",
    "dataset](https://www.studeersnel.nl/nl/document/vrije-universiteit-amsterdam/machine-learning/alternative-to-the-boston-housing-data/1905848).\n",
    "Which can be obtained from Sklearn in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "housing = fetch_openml(name=\"house_prices\", as_frame=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But its description is even less detailed than California's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(housing.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "\n",
    "Let's continue with the California housing dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "california.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Features:\", california.data.shape, california.data.dtype)\n",
    "print(\"Target:\", california.target.shape, california.target.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One DataFrame for everything\n",
    "df_ca = pd.DataFrame(california.data, columns=california.feature_names)\n",
    "df_ca['TARGET'] = california.target\n",
    "df_ca.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might wonder what the units are for the target variable of house price.  Consulting the [function documentation](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html) we can determine that is multiples of $100,000 (presumably 1997 dollars and prices, given citation).\n",
    "\n",
    "Looking at some summary statistics is always worthwhile before we jump into our actual model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ca.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing a Gaggle of Regressors\n",
    "\n",
    "The DataFrame is useful for getting sense of the data, but for scikit-learn itself, we simply want to work with the `.data` and `.target` arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = california.data\n",
    "y = california.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For validation—as usual—we want a train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metrics we use in the below code are `explained_variance_score`, `mean_absolute_error`, and `r2_score`. Many other metrics are are available, mostly within the `sklearn.metrics` submodule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The particular regressors we choose does not reflect any deep decision. Most are somewhat in the family of linear regression. RANSAC is tried because it is meant to be more resilient against outliers in data. This is sometimes more strongly predictive than generic linear regression. One of several Gaussian techniques is shown as an example—it behaves worthlessly for this example, at least without hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.linear_model import LinearRegression, RANSACRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "\n",
    "regressors = [\n",
    "    LinearRegression(),\n",
    "    RANSACRegressor(),\n",
    "    KNeighborsRegressor(),\n",
    "    KNeighborsRegressor(n_neighbors=9, metric=\"manhattan\"),\n",
    "    SVR(),\n",
    "    LinearSVR(),\n",
    "    GaussianProcessRegressor(),\n",
    "    SVR(kernel=\"linear\"),  # Cf. LinearSVR: much slower, might be better or worse:\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = 6\n",
    "for model in regressors[:head]:\n",
    "    start = time()\n",
    "    model.fit(X_train, y_train)\n",
    "    train_time = time() - start\n",
    "    start = time()\n",
    "    predictions = model.predict(X_test)\n",
    "    predict_time = time()-start    \n",
    "    print(model)\n",
    "    print(f\"\\tTraining time: {train_time:0.3f} s\")\n",
    "    print(f\"\\tPrediction time: {predict_time:0.3f} s\")\n",
    "    print(f\"\\tExplained variance: {explained_variance_score(y_test, predictions)}\")\n",
    "    print(f\"\\tMean absolute error: {mean_absolute_error(y_test, predictions)}\")\n",
    "    print(f\"\\tR2 score: {r2_score(y_test, predictions)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two models that are very slow to train are omitted in the \"live\" output in this course.  Those outputs would be the following:\n",
    "\n",
    "```\n",
    "GaussianProcessRegressor(alpha=1e-10, copy_X_train=True, kernel=None,\n",
    "             n_restarts_optimizer=0, normalize_y=False,\n",
    "             optimizer='fmin_l_bfgs_b', random_state=None)\n",
    "    Training time: 161.517s\n",
    "    Prediction time: 4.571s\n",
    "    Explained variance: -0.0199393545636\n",
    "    Mean absolute error: 1.91320341763\n",
    "    R2 score: -2.79445305731\n",
    "    \n",
    "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
    "  kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
    "    Training time: 4458.012s\n",
    "    Prediction time: 0.843s\n",
    "    Explained variance: 0.527882057056\n",
    "    Mean absolute error: 0.601893862699\n",
    "    R2 score: 0.517431654021\n",
    "```\n",
    "\n",
    "Neither has a very good R2 value for this particular data.  `GaussianProcessRegressor` is actually negative (which is very bad). `SVR` with a linear kernel is moderately good, but no better than simple `LinearRegression'.  Note, however, that even though the training took well over an hour, the prediction takes less than a second.  This is not the fastest predictor, but it is not the slowest among those that train orders of magnitude faster.  If this model performs best, it may be worth spending the one-time cost to train and then be able to regress sufficiently quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Models\n",
    "\n",
    "With high dimensionality, plain linear regression tends to perform surprisingly well.  Variants may add improvements, but this technique from general statistics, or analytic math, is quite good—notwithstanding that it basically pre-dates machine learning per se.  A simple linear regression basically assumes the following:\n",
    "\n",
    "* as a feature value varies, the target value varies proportionally\n",
    "  * responses to features are global\n",
    "  * responses are strictly linear\n",
    "* features are not co-linear\n",
    "\n",
    "Even if these assumptions are not stricly true, the model may perform well.  One common strategy to mitigate variance from these assumptions is to *penalize* the weights (coefficients) assigned to each feature.  An \"$l1$ penalty\" is known as Lasso regression and will force some coefficients to zero.  An $l2$ penalty is known as Ridge regression and damps coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equations and Visualizations for Penalties\n",
    "\n",
    "In more detail, plain linear regression is this calculation:\n",
    "\n",
    "$$ \\text{min}_{w, b} \\sum_i || w^\\mathsf{T}x_i + b  - y_i||^2 $$\n",
    "\n",
    "For Lasso regression (**L**east **a**bsolute **s**hrinkage **s**election **o**perator), the equation is:\n",
    "\n",
    "$$ \\text{min}_{w, b} \\sum_i || w^\\mathsf{T}x_i + b  - y_i||^2  + \\alpha ||w||_1$$\n",
    "\n",
    "For Ridge regression, the equation is:\n",
    "\n",
    "$$ \\text{min}_{w,b}  \\sum_i || w^\\mathsf{T}x_i + b  - y_i||^2  + \\alpha ||w||_2^2$$ \n",
    "\n",
    "The second term in the right hand side of the equation below is the L2 regularization that is part of ridge regression ($\\alpha$ is usually chosen between 0.01 and 100).  The idea in Ridge regression is to mutually minimize the error terms and the penalty constant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is probably easier to visualize these than look at the equations.  Ridge regression may be a good choice when there are colinear predictors in the `X` matrix.  In the simplest characterization, Ridge pulls the OLS (ordinary least square) estimators closer to zero (but not actually set them to exactly zero).\n",
    "\n",
    "![Geometric Interpretation of Ridge Regression](img/ridge_regression_geomteric.png)\n",
    "\n",
    "Contrasting Lasso and Ridge (or $l1$ versus $l2$) we can visualize the difference as below.  Notice that some coefficients are actually zeroes in the Lasso model.\n",
    "\n",
    "![L1 versus L2 regions](img/L1_and_L2_balls.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try this all out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge\n",
    "\n",
    "lr = LinearRegression()\n",
    "lasso = Lasso()\n",
    "ridge = Ridge()\n",
    "\n",
    "for model in [lr, lasso, ridge]:\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    print(model)\n",
    "    print(\"\\tExplained variance:\", explained_variance_score(y_test, predictions))\n",
    "    print(\"\\tMean absolute error:\", mean_absolute_error(y_test, predictions))\n",
    "    print(\"\\tR2 score:\", r2_score(y_test, predictions))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pitfalls of Linear Models\n",
    "\n",
    "Famously, there can be many features of data that are not well captured in any (naïve) linear model. [Francis Anscombe](https://en.wikipedia.org/wiki/Frank_Anscombe) created his [Anscombe's quartet](https://en.wikipedia.org/wiki/Anscombe%27s_quartet) as an illustration of this. The several distributions in it have nearly the same or identical means and variances along X and Y axes, have almost the same correlations of X and Y, have the same linear regression lines and coefficient of determination. \n",
    "\n",
    "Let us look at some basic statistics and regressions on this data. Let us also look at the statistical properties of the elements of the quartet. In particular, notice the means and standard deviations (of both the x and y features), and the min/max and quartiles of the first three x feature collections.\n",
    "\n",
    "This sample dataset is included in the Seaborn visualization library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset(\"anscombe\")\n",
    "df.pivot(columns='dataset').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall data collection has similar (but not quite identical) properties to its subsects.\n",
    "\n",
    "We might hope to tease apart what is going on with the several subsets by looking at the correlation of the features. Other than some floating point approximations, these are also identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df_1 = df[df.dataset == \"I\"]\n",
    "df_2 = df[df.dataset == \"II\"]\n",
    "df_3 = df[df.dataset == \"III\"]\n",
    "df_4 = df[df.dataset == \"IV\"]\n",
    "\n",
    "(\n",
    "    np.corrcoef(df_1.x, df_1.y)[1, 0],\n",
    "    np.corrcoef(df_2.x, df_2.y)[1, 0],\n",
    "    np.corrcoef(df_3.x, df_3.y)[1, 0],\n",
    "    np.corrcoef(df_4.x, df_4.y)[1, 0],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually visualizing the data gives us a very distinctly different impression of the data subsets.  The linear regressions are identical (under an [ordinary least squares fit](https://en.wikipedia.org/wiki/Ordinary_least_squares) here, but the point would be the same with a different fitting regime)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Show the results of a linear regression within each dataset\n",
    "sns.lmplot(\n",
    "    x=\"x\", y=\"y\", col=\"dataset\", hue=\"dataset\", data=df,\n",
    "    col_wrap=2, palette=\"muted\", height=4,\n",
    "    scatter_kws={\"s\": 50, \"alpha\": 1}\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Datasaurus\n",
    "\n",
    "Humorously, Justin Matejka and George Fitzmaurice give a similar example with the [Datasaurus](https://www.autodeskresearch.com/publications/samestats) in _Same Stats, Different Graphs: Generating Datasets with Varied Appearance and Identical Statistics through Simulated Annealing_:\n",
    "\n",
    "<img src=\"img/DataDino-600x455.gif\" width=\"50%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Moral of the Pitfalls\n",
    "\n",
    "Obviously, the concerns raised by Anscombe hardly mean we should not use linear models.  In the examples we have looked at, basic OLS linear regression performed as well or better than all the other models we tried.  But there are certainly special cases where linear regression will be unable to distingish distributions whereas other techniques might be able to.\n",
    "\n",
    "There is a tradeoff in these kinds of situations between two approaches.  One approach would be to use more feature engineering and general data cleanup before we get to our linear regression step.  We will think about those possibilities in later chapters.  Another approach is to choose a different family of model from the start, and avoid the particular pitfalls the linear models have (but encounter other pitfalls in their place)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-linear Regressors\n",
    "\n",
    "Scikit-learn has a large number of additional regression models that are not based on linear models.  One relatively easy one to understand is `DecisionTreeRegressor`.  \n",
    "\n",
    "The code below is adapted slightly from the [scikit-learn documentation](http://scikit-learn.org/stable/auto_examples/tree/plot_tree_regression.html#sphx-glr-auto-examples-tree-plot-tree-regression-py). Here we add an Epsilon-Support Vector Regression (`SVR`) regressor as well as a decision tree to show the contrast.\n",
    "\n",
    "In the below one dimensional dataset, SVR produced a smoothed result that is much closer to the jittered sine curve that was used generate the points.  That is not really the point to the example though.  We want to get a visual sense of the kind of thing a decision tree is doing as a regressor rather than a classifier.  In higher dimensional cases, deciding continuous cut-points is often more effective than a smoothed kernel (and non-synthetic data isn't necessarily so smooth to start with). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run src/decisiontree_regressor.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that `DecisionTreeRegressor` is conceptually similar to `DecisionTreeClassifier`.  At certain cut-points in the data (here just one dimension) a switch is made to a different target value.  However, rather than simply predict a flipped boolean value as in the prior lesson, we predict a new quantitative level for the target around cut points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-linearity in California Housing\n",
    "\n",
    "Let us try a decision tree style against the multi-dimensional California housing data.  So far, a simple `LinearRegression` was the best we had done against this dataset.  As well as `DecisionTreeRegressor` of several different depths, we will add in `RandomForestRegressor`.  From [the documentation](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html):\n",
    "\n",
    "> A random forest is a meta estimator that fits a number of classifying decision trees on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    california.data, california.target, random_state=1\n",
    ")\n",
    "\n",
    "regressors = [\n",
    "    LinearRegression(),\n",
    "    DecisionTreeRegressor(max_depth=5),\n",
    "    DecisionTreeRegressor(max_depth=10),\n",
    "    DecisionTreeRegressor(max_depth=20),\n",
    "    RandomForestRegressor(max_depth=10),\n",
    "    GradientBoostingRegressor(n_estimators=200),\n",
    "    SVR(),\n",
    "]\n",
    "\n",
    "for model in regressors:\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    print(model)\n",
    "    print(f\"\\tExplained variance: {explained_variance_score(y_test, predictions)}\")\n",
    "    print(f\"\\tMean absolute error: {mean_absolute_error(y_test, predictions)}\")\n",
    "    print(f\"\\tR2 score: {r2_score(y_test, predictions)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At least three things to note about this latest set of comparisons:\n",
    "\n",
    "* SVR (with an RBF kernel) does very poorly.  Smoothing around a kernel does not necessarily produce the best results.  Intuitively, I would expect this because house prices tend to fall into plateaus around certain characteristics (e.g., houses in cities at certain latitude/longitude locations are characteristically expensive or cheap, depending on the city).\n",
    "* The quality of a decision tree is sensitive to its depth.  The `max_depth` of 10 may or may not be optimal, but some higher and lower values are worse.\n",
    "* As widely expected, a random forest improves on a decision tree.  Because the nodes and their order are partially randomized, averaging a collection (10 by default) of them tends to produce a better result.  These algorithms are not among the most expensive, but averaging ten decision trees will easily take 10 times as much time or cores as a single tree.\n",
    "* A `GradientBoostingRegressor` works best here, by a small margin.  This is an ensemble like the `RandomForestRegressor`, but it works a bit differently.  Instead of simply training many relatively deep trees, a gradient boosting approach fits very shallow trees one after the other.  Each new weak predictor does not try to predict from the initial features to the target, but is a prediction from the residuals (the errors) of the last predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Lesson\n",
    "\n",
    "**Hyperparameters**: In the current lessson we looked at several regression models, with a particular focus on both the strength and the limits of linear models.\n",
    "\n",
    "To some extent, we have utilized hyperparameters in passing at many places in these lessons.  The next lesson will focus on working with hyperparameters more systematically.\n",
    "\n",
    "<a href=\"SKLearn-05_Hyperparameters.ipynb\"><img src=\"img/open-notebook.png\" align=\"left\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "Materials licensed under [CC BY-NC-ND 4.0](https://creativecommons.org/licenses/by-nc-nd/4.0/) by the authors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
